{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import matplotlib as matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from platform import python_version\n",
    "\n",
    "# Definitions of certain constants\n",
    "DAY = datetime.timedelta(days=1)\n",
    "\n",
    "ERAIN_DESC = \"erain perturbing etcp\"\n",
    "SIMUL_DESC = \"Software simulation\"\n",
    "IRR_DESC = \"Irrigation perturbing etcp\"\n",
    "NULL_PROFILE_DESC = \"Null profile value\"\n",
    "HUGE_PROFILE_DIP_DESC = \"Huge profile dip\"\n",
    "LARGE_PROFILE_DIP_DESC = \"Large profile dip\"\n",
    "HU_STUCK_DESC = \"Heat Units `stuck`\"\n",
    "ET0_STUCK_DESC = \"et0 `stuck`\"\n",
    "ETCP_POS_DESC = \"etcp is positive\"\n",
    "ETCP_OUTLIERS_DESC = \"etcp outliers\"\n",
    "LUX_DESC = \"Luxurious water uptake\"\n",
    "\n",
    "ET0_MAX = 12\n",
    "KCP_MAX = 0.8\n",
    "ETCP_MAX = ET0_MAX * KCP_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henri is using Python version 3.6.8.  You are using Python version 3.6.8.\n",
      "Henri is using numpy version 1.15.4.  You are using numpy version 1.15.4.\n",
      "Henri is using pandas version 0.24.0.  You are using pandas version 0.24.0.\n",
      "Henri is using matplotlib version 2.2.3.  You are using matplotlib version 2.2.3.\n"
     ]
    }
   ],
   "source": [
    "print(\"Henri is using Python version 3.6.8.  You are using Python version {}.\".format(python_version()))\n",
    "print(\"Henri is using numpy version 1.15.4.  You are using numpy version {}.\".format(np.__version__))\n",
    "print(\"Henri is using pandas version 0.24.0.  You are using pandas version {}.\".format(pd.__version__))\n",
    "print(\"Henri is using matplotlib version 2.2.3.  You are using matplotlib version {}.\".format(matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_ids = [\"P-370\", \"P-371\", \"P-372\", \"P-384\", \"P-391\", \"P-392\", \"P-891\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flagger(bad_dates, brief_desc):\n",
    "    \"\"\"\n",
    "    Flag bad_dates with a binary value of 1 and append a brief description about why bad_dates were flagged.\n",
    "    \n",
    "    Parameters:\n",
    "    bad_dates (pandas.core.indexes.datetimes.DatetimeIndex):  Dates for which we cannot calculate k_cp because our readings were perturbed and rendered unuseful.\n",
    "    brief_desc (str):  A very short description about why bad_dates were flagged.\n",
    "    \n",
    "    Returns:\n",
    "    None.  It updates the DataFrame storing all the information related to flagging.  In this case the DataFrame is called `df_flag`    \n",
    "    \"\"\"\n",
    "    if df_flag.loc[bad_dates, \"description\"].str.contains(brief_desc).all(axis=0):\n",
    "        # The bad_dates have already been flagged for the reason given in brief_desc.\n",
    "        # No use in duplicating brief_desc contents in the description column.\n",
    "        # Therefore redundant information in the df_flag DataFrame is avoided.\n",
    "        print(\"You have already flagged these dates for the reason given in `brief_desc`; No flagging has taken place.\")\n",
    "        return\n",
    "    else:\n",
    "        df_flag.loc[bad_dates, \"binary_value\"] = 1\n",
    "        df_flag.loc[bad_dates, \"description\"] += (\" \" + brief_desc + \".\")\n",
    "        df_flag.loc[:, \"description\"] = df_flag.loc[:, \"description\"].apply(lambda s: s.lstrip().rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporter(brief_desc, remaining=False):\n",
    "    tally = df_flag[\"description\"].str.contains(brief_desc).sum()\n",
    "    n_tot_entries = len(df_flag.index)\n",
    "    perc = tally / n_tot_entries * 100\n",
    "    print(\"{:.1f}% of data is affected due to [{}].\".format(perc, brief_desc))\n",
    "    \n",
    "    if remaining:\n",
    "        calc = 100 - df_flag[\"binary_value\"].sum()/len(df_flag.index)*100\n",
    "        print(\"After all the flagging that has taken place in this entire notebook, only {:.0f}% of your data is useful.\".format(calc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_redundant_columns(df):\n",
    "    labels = [\"rzone\", \"available\", \"days_left\", \"deficit_current\", \n",
    "              \"rzm\", \"fcap\", \"deficit_want\", \"refill\", \"et0_forecast_yr\"]\n",
    "    df_returned = df.drop(labels=labels, axis=1)\n",
    "    return df_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_erain_events(df):\n",
    "    df_rain = data.filter([\"rain\", \"erain\"], axis=1)\n",
    "    \n",
    "    condition = (df_rain[\"erain\"] > 0) & (df[\"total_irrig\"] == 0) & (df[\"etcp\"] > 0)\n",
    "    erain_dates = df_rain[condition].index\n",
    "    \n",
    "    flagger(bad_dates=erain_dates, brief_desc=ERAIN_DESC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_simulated_events(df):\n",
    "    condition = data[\"rzm_source\"].str.contains(\"software\")\n",
    "    flag_software_dates = data[condition].index\n",
    "    \n",
    "    flagger(bad_dates=flag_software_dates, brief_desc=SIMUL_DESC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_irrigation_events(df):\n",
    "    df_irr = df.filter([\"total_irrig\"], axis=1)\n",
    "    \n",
    "    conditions = (df_irr[\"total_irrig\"] > 0) & (df[\"etcp\"] > 0) & (df[\"rain\"] == 0)\n",
    "    flag_irrigation_dates = df[conditions].index\n",
    "    \n",
    "    flagger(bad_dates=flag_irrigation_dates, brief_desc=IRR_DESC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_suspicious_and_missing_profile_events(df):\n",
    "    df_profile = df.filter([\"profile\"], axis=1)\n",
    "    df_profile[\"difference\"] = df_profile[\"profile\"].diff()\n",
    "    \n",
    "    df_profile[\"profile\"].replace(0.0, np.nan, inplace=True)\n",
    "    condition = df_profile[\"profile\"].isnull()\n",
    "    bad_profile_days = df_profile[condition].index\n",
    "    flagger(bad_dates=bad_profile_days, brief_desc=NULL_PROFILE_DESC)\n",
    "    \n",
    "    huge_dip_days = []\n",
    "    for d in df_profile.index:\n",
    "        try:\n",
    "            if (df_profile.loc[d, \"difference\"] < 0) and pd.isnull(df_profile.loc[d + DAY, \"profile\"]):\n",
    "                huge_dip_days.append(d)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    huge_dip_days = pd.to_datetime(huge_dip_days)\n",
    "    flagger(bad_dates=huge_dip_days, brief_desc=HUGE_PROFILE_DIP_DESC)\n",
    "    df_profile.loc[huge_dip_days, [\"profile\"]] = np.nan\n",
    "    df.loc[huge_dip_days, [\"profile\"]] = np.nan\n",
    "    \n",
    "    df_profile.loc[huge_dip_days ,[\"difference\"]] = np.nan\n",
    "    negative_differences = df_profile[df_profile[\"difference\"] < 0][\"difference\"].values\n",
    "    percentile_value = np.quantile(negative_differences, q=[0.01, 0.015, 0.02])[2]\n",
    "    large_dip_days = []\n",
    "    for d in df_profile.index:\n",
    "        try:\n",
    "            if (df_profile.loc[d, \"difference\"] < percentile_value) and (df_profile.loc[d + DAY, \"difference\"] > 0):\n",
    "                large_dip_days.append(d)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    large_dip_days = pd.to_datetime(large_dip_days)\n",
    "    flagger(bad_dates=large_dip_days, brief_desc=LARGE_PROFILE_DIP_DESC)\n",
    "    df_profile.loc[large_dip_days, [\"profile\"]] = np.nan\n",
    "    df.loc[large_dip_days, [\"profile\"]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_spurious_heat_units(df):\n",
    "    df_gdd = df.filter([\"heat_units\"], axis=1)\n",
    "    df_gdd[\"hu_diff1\"] = df_gdd[\"heat_units\"].diff(periods=1)\n",
    "    df_gdd[\"hu_diff2\"] = df_gdd[\"heat_units\"].diff(periods=2)\n",
    "    condition = (df_gdd[\"hu_diff1\"] == 0.0) | (df_gdd[\"hu_diff2\"] == 0)\n",
    "    bad_hu_days = df_gdd[condition].index\n",
    "    flagger(bad_dates=bad_hu_days, brief_desc=HU_STUCK_DESC)\n",
    "    df_gdd.loc[bad_hu_days, [\"heat_units\"]] = 0.0\n",
    "    df.loc[bad_hu_days, [\"heat_units\"]] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_spurious_et0(df):\n",
    "    df_et0 = df.filter([\"et0\"], axis=1)\n",
    "    df_et0[\"et0_diff1\"] = df_et0[\"et0\"].diff(periods=1)\n",
    "    df_et0[\"et0_diff2\"] = df_et0[\"et0\"].diff(periods=2)\n",
    "    condition = (df_et0[\"et0_diff1\"] == 0.0) | (df_et0[\"et0_diff2\"] == 0)\n",
    "    bad_et0_days = df_et0[condition].index\n",
    "    flagger(bad_dates=bad_et0_days, brief_desc=ET0_STUCK_DESC)\n",
    "    df_et0.loc[bad_et0_days, [\"et0\"]] = np.nan\n",
    "    df.loc[bad_et0_days, [\"et0\"]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_unwanted_etcp(df):\n",
    "    df_etcp = df.filter([\"etcp\"], axis=1)\n",
    "    \n",
    "    condition = df_etcp[\"etcp\"] >= 0.0\n",
    "    positive_etcp_days = df_etcp[condition].index\n",
    "    flagger(bad_dates=positive_etcp_days, brief_desc=ETCP_POS_DESC)\n",
    "    df_etcp.loc[positive_etcp_days, [\"etcp\"]] = np.nan\n",
    "    df.loc[positive_etcp_days, [\"etcp\"]] = np.nan\n",
    "    \n",
    "    condition = df[\"binary_value\"] == 1\n",
    "    junk_data_dates = df[condition].index\n",
    "    df_etcp.loc[junk_data_dates, [\"etcp\"]] = np.nan\n",
    "    df.loc[junk_data_dates, [\"etcp\"]] = np.nan\n",
    "    \n",
    "    # to simply programming, multiply `etcp` column with -1\n",
    "    df_etcp[\"etcp\"] = df_etcp[\"etcp\"].multiply(-1, fill_value=np.nan)\n",
    "    df[\"etcp\"] = df[\"etcp\"].multiply(-1, fill_value=np.nan)\n",
    "    \n",
    "    condition = df_etcp[\"etcp\"] > ETCP_MAX\n",
    "    etcp_outlier_dates = df_etcp[condition].index\n",
    "    df_etcp.loc[etcp_outlier_dates, [\"etcp\"]] = np.nan\n",
    "    df.loc[etcp_outlier_dates, [\"etcp\"]] = np.nan\n",
    "    flagger(bad_dates=etcp_outlier_dates, brief_desc=ETCP_OUTLIERS_DESC)\n",
    "    \n",
    "    condition = df_etcp[\"etcp\"] > df[\"et0\"].mul(KCP_MAX, fill_value=np.nan)\n",
    "    luxurious_dates = df_etcp[condition].index\n",
    "    df_etcp.loc[luxurious_dates, [\"etcp\"]] = np.nan\n",
    "    df.loc[luxurious_dates, [\"etcp\"]] = np.nan\n",
    "    flagger(bad_dates=luxurious_dates, brief_desc=LUX_DESC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
