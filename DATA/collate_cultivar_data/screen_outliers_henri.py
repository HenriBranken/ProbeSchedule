import pandas as pd
import numpy as np
import helper_functions as h
import math
from cleaning_operations import BEGINNING_MONTH, KCP_MAX
import datetime
import matplotlib.pyplot as plt
pd.options.mode.chained_assignment = None  # default='warn'


# =============================================================================
# Define some other important constants
# =============================================================================
n_neighbours_list = list(np.arange(start=30, stop=1-1, step=-1))
delta_x = 1
x_limits = [0, 365]
quantile = 0.97
n_iterations = 5
marker_list = ["o", ">", "<", "s", "P", "*", "X", "D"]
color_list = ["red", "gold", "seagreen", "lightseagreen", "royalblue",
              "darkorchid", "plum", "burlywood"]
# =============================================================================


# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Import all the necessary data
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# 1. Import the cleaned (scatterplot) data of kcp versus datetimeStamp.
# 2. Import the (first) kcp vs datetimestamp trend generated by a WMA.
# 3.
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Extract the starting year.  The year of the most "historic/past" sample.
with open("./data/starting_year.txt", "r") as f:
    starting_year = int(f.readline().rstrip())
start_date = datetime.datetime(year=starting_year, month=BEGINNING_MONTH,
                               day=1)

# 1.
# Load the cleaned (scatterplot) data of kcp versus datetimeStamp from
# `./data/stacked_cleaned_data_for_overlay.xlsx` that was saved in
# `step_1_perform_cleaning.py`.  We are interested in the `datetimeStamp`
# index, and the newly created `days` column.
cleaned_df = pd.read_excel("./data/stacked_cleaned_data_for_overlay.xlsx",
                           header=0, index_col=[0, 1], parse_dates=True)
outer_index = list(cleaned_df.index.get_level_values("probe_id").unique())
inner_index = list(cleaned_df.index.get_level_values("datetimeStamp").unique())
cleaned_df.index = cleaned_df.index.droplevel(0)
cleaned_df.sort_index(axis=0, level="datetimeStamp", ascending=True,
                      inplace=True)
cleaned_df["days"] = cleaned_df.index - start_date
cleaned_df["days"] = cleaned_df["days"].dt.days
x_scatter = cleaned_df["days"].values
y_scatter = cleaned_df["kcp"].values

# 2.
# Import the (first/beginning) kcp vs datetimestamp smoothed trend from
# `binned_kcp_data.xlsx`.  We need to import the sheet `day_frequency` from
# `binned_kcp_data.xlsx`.  We are interested in the `season_day` column, and
# the `day_averaged_kcp` column.
smoothed_kcp_vs_date_df = pd.read_excel("./data/binned_kcp_data.xlsx",
                                        sheet_name="day_frequency", header=0,
                                        index_col=0, parse_dates=True,
                                        squeeze=False)
x_smoothed = smoothed_kcp_vs_date_df["season_day"].values
y_smoothed = smoothed_kcp_vs_date_df["day_averaged_kcp"].values

# 3.
# Instantiate a pandas DataFrame containing the reference crop coefficient
# values.
cco_df = pd.read_excel("./data/reference_crop_coeff.xlsx", sheet_name=0,
                       header=0, index_col=0, parse_dates=True)
cco_df["days"] = cco_df.index - datetime.datetime(year=starting_year,
                                                  month=BEGINNING_MONTH,
                                                  day=1)
cco_df["days"] = cco_df["days"].dt.days  # we use the dt.days attribute

# 4.
# What was the `mode` used in `step_3_smoothed_version.py`.  If it was
# "Polynomial-fit", then it is not possible to proceed with "WMA", and we can
# only proceed with "Polynomial-fit".  If it was originally "WMA", then we may
# try and proceed with "WMA", however it might be necessary to switch over to
# "Polynomial-fit" as we progress through the iterations.
with open("./data/mode.txt", "r") as f:
    mode = f.readline().rstrip()
print("The mode is: {}.".format(mode))
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


# =============================================================================
# Initialise the "starting points" corresponding to iteration `i = 0`.
# =============================================================================
r_squared_stat = h.get_r_squared(x_raw=x_scatter, y_raw=y_scatter,
                                 x_fit=x_smoothed, y_fit=y_smoothed)
xy_scatter_df = h.create_xy_df(x_vals=x_scatter, y_vals=y_scatter,
                               iteration=int(0), status="scatter")
xy_smoothed_df = h.create_xy_df(x_vals=x_smoothed, y_vals=y_smoothed,
                                iteration=int(0), status="smoothed")
# =============================================================================


# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Data Munging.  In the for-loop we iteratively remove the "farthest" outliers.
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
r_squared_stat_list = [r_squared_stat]
xy_scatter_dfs = [xy_scatter_df]
xy_smoothed_dfs = [xy_smoothed_df]

for i in range(n_iterations):
    deviations = h.get_offsets_from_trendline(x_raw=x_scatter,
                                              y_raw=y_scatter,
                                              x_fit=x_smoothed,
                                              y_fit=y_smoothed)
    interim_df = h.create_interim_df(x_raw=x_scatter,
                                     y_raw=y_scatter, dev=deviations)
    values = np.quantile(interim_df["dev"].values, q=quantile)
    x_scatter, y_scatter = \
        h.create_new_generation_xy_scatter(dataframe=interim_df,
                                           threshold=values)
    xy_scatter_dfs.append(h.create_xy_df(x_vals=x_scatter, y_vals=y_scatter,
                                         iteration=int(i + 1),
                                         status="scatter"))
    if mode == "WMA":
        saved_trend_lines = []
        num_bumps = []
        tracker = 0
        for n_neighbours in n_neighbours_list:
            try:
                x_smoothed, y_smoothed = \
                    h.weighted_moving_average(x=x_scatter, y=y_scatter,
                                              step_size=delta_x,
                                              width=n_neighbours,
                                              x_lims=x_limits)
                saved_trend_lines.append(zip(x_smoothed, y_smoothed))
                num_bumps.append(h.get_n_local_extrema(y_smoothed))
                tracker += 1
            except ZeroDivisionError:
                n_neighbours_list = n_neighbours_list[:tracker]  # truncate
                break  # exit the for-loop.
        try:
            prized_index = h.get_prized_index(num_bumps)
            trend_line = saved_trend_lines[prized_index]
            unpack = [list(t) for t in zip(*trend_line)]
            x_smoothed, y_smoothed = unpack[0], unpack[1]
        except h.NoProperWMATrend as e:
            print(e)
            print("{:.>80}".format("Cannot perform Exponentially-Weighted-"
                                   "Moving-Average."))
            print("{:.>80}".format("Proceeding with Polynomial Fit."))
            mode = "Polynomial-fit"  # Switch over to "Polynomial-fit" mode.
            x_smoothed, y_smoothed = \
                h.get_final_polynomial_fit(x_raw=x_scatter, y_raw=y_scatter,
                                           step_size=delta_x,
                                           degree=h.pol_degree,
                                           x_lims=x_limits)
    else:  # i.e. we know for sure that mode is "Polynomial-fit"
        x_smoothed, y_smoothed = \
            h.get_final_polynomial_fit(x_raw=x_scatter, y_raw=y_scatter,
                                       step_size=delta_x, degree=h.pol_degree,
                                       x_lims=x_limits)

    xy_smoothed_dfs.append(h.create_xy_df(x_vals=x_smoothed, y_vals=y_smoothed,
                                          iteration=int(i + 1),
                                          status="smoothed"))
    r_squared_stat = h.get_r_squared(x_raw=x_scatter, y_raw=y_scatter,
                                     x_fit=x_smoothed, y_fit=y_smoothed)
    r_squared_stat_list.append(r_squared_stat)
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


# -----------------------------------------------------------------------------
# Stack all the dataframes together into a MultiIndex DataFrame
# -----------------------------------------------------------------------------
xy_scatter_df = pd.concat(xy_scatter_dfs, ignore_index=False, sort=False,
                          copy=True)
xy_scatter_df = xy_scatter_df.set_index(["iteration", xy_scatter_df.index])

xy_smoothed_df = pd.concat(xy_smoothed_dfs, ignore_index=False, sort=False,
                           copy=True)
xy_smoothed_df = xy_smoothed_df.set_index(["iteration", xy_smoothed_df.index])
# -----------------------------------------------------------------------------


# =============================================================================
# Plot all the results in an array of figures
# =============================================================================
num_cols = 2
num_rows = int(math.ceil(len(r_squared_stat_list) / num_cols))
season_xticks = list(np.arange(start=x_limits[0], stop=x_limits[1], step=30))

fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(7.07, 10))
axs = axs.flatten()
plt.subplots_adjust(wspace=0.05)
fig.suptitle("$k_{cp}$ versus Number of Days.  "
             "Outliers removed in iterative cycles.")
fig.autofmt_xdate()

for i, ax in enumerate(axs):
    print("The value of i is: {}.".format(i))
    ax.set_ylim(bottom=0.0, top=KCP_MAX)
    ax.grid(True)
    x_scatter, y_scatter = h.get_xs_and_ys(dataframe=xy_scatter_df,
                                           iteration=i, status="scatter")
    x_smoothed, y_smoothed = h.get_xs_and_ys(dataframe=xy_smoothed_df,
                                             iteration=i, status="smoothed")
    ax.scatter(x_scatter, y_scatter, marker=".", color="magenta", s=20,
               edgecolors="black", linewidth=1, alpha=0.5,
               label="Scatter plot")
    ax.scatter(cco_df["days"].values, cco_df["cco"].values, marker=".",
               color="yellow", s=15, alpha=0.5, label="Reference $k_{cp}$")
    ax.plot(x_smoothed, y_smoothed, linewidth=1.5, alpha=0.75,
            label="Smoothed")
    ax.tick_params(which="major", bottom=True, labelbottom=True,
                   colors="black", labelcolor="black", labelsize="small",
                   axis="x")
    ax.set_xticks(season_xticks)
    ax.set_xticklabels(season_xticks, rotation=40, ha="right")
    ax.set_xlim(left=x_limits[0], right=x_limits[1])
    ax.set_ylim(bottom=0, top=KCP_MAX)
    for tick in ax.get_xticklabels():
        tick.set_visible(True)
    ax.legend(prop={"size": 6}, loc=6)
    ax.annotate(s="$R^2$ = {:.3f}\nIteration {}".format(r_squared_stat_list[i],
                                                        i),
                xycoords="axes fraction",
                xy=(0.01, 0.87), fontsize=9)
for m in [0, 2, 4]:
    axs[m].set_ylabel("$k_{cp}$")
for m in [4, 5]:
    axs[m].set_xlabel("Days")
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig("./figures/remove_outliers_henri_method.png")
plt.close()
# =============================================================================
